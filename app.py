import streamlit as st
import pandas as pd
import openai
import faiss
import numpy as np

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
st.set_page_config(page_title="Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ Ù†ØµÙˆØµ Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ©", layout="wide")
st.title("ğŸ“š Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ Ù†ØµÙˆØµ Ø´ÙŠØ® Ø§Ù„Ø¥Ø³Ù„Ø§Ù… Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ©")

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
openai_key = st.sidebar.text_input("ğŸ” Ø£Ø¯Ø®Ù„ Ù…ÙØªØ§Ø­ OpenAI", type="password")

model_choice = st.sidebar.selectbox(
    "ğŸ” Ø§Ø®ØªØ± Ù†Ù…ÙˆØ°Ø¬ OpenAI",
    options=[
        "gpt-4o",         # Ø£Ø­Ø¯Ø« Ù†Ù…ÙˆØ°Ø¬
        "gpt-4-turbo",    # Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† GPT-4
        "gpt-3.5-turbo"   # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£Ø³Ø±Ø¹ ÙˆØ§Ù„Ø£Ø±Ø®Øµ
    ],
    index=0
)

embedding_model = "text-embedding-ada-002"

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
@st.cache_resource
def load_data():
    df = pd.read_csv("dar1_with_embeddings.csv")
    index = faiss.read_index("faiss_dar1.index")
    return df, index

df, index = load_data()

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ embedding
def get_embedding(text):
    from openai import OpenAI
    client = OpenAI(api_key=openai_key)
    response = client.embeddings.create(input=[text.replace("\n", " ")], model=embedding_model)
    return response.data[0].embedding

# Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
def search_semantic(query, top_k=5, threshold=0.35):
    query_vec = np.array(get_embedding(query)).astype("float32").reshape(1, -1)
    distances, indices = index.search(query_vec, top_k)

    results = []
    for i, dist in enumerate(distances[0]):
        if dist < threshold:
            match = df.iloc[indices[0][i]]
            results.append((match, dist))

    return results

# ØªÙØ³ÙŠØ± Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©
def explain_match(query, match_text):
    prompt = f"""Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "{query}"
Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„Ø§Ù… Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ©: "{match_text}"

Ø§Ø´Ø±Ø­ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„Ù†Øµ ÙˆØ§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù„ØºØ© Ø¹Ù„Ù…ÙŠØ© ÙˆØ§Ø¶Ø­Ø©:"""
    
    from openai import OpenAI
    client = OpenAI(api_key=openai_key)
    response = client.chat.completions.create(
        model=model_choice,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )
    return response.choices[0].message.content

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
query = st.text_input("ğŸ“ Ø£Ø¯Ø®Ù„ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ", placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù…ÙˆÙ‚Ù Ø§Ø¨Ù† ØªÙŠÙ…ÙŠØ© Ù…Ù† ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¹Ù‚Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ù„ØŸ")

if query and openai_key:
    with st.spinner("ğŸ” Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
        results = search_semantic(query, top_k=3)

        for i, row in results.iterrows():
            st.markdown(f"### ğŸ”¹ Ø§Ù„Ù†Øµ {i+1}")
            st.write(row['text'])

            with st.expander("ğŸ§  ØªÙØ³ÙŠØ± Ø§Ù„Ø¹Ù„Ø§Ù‚Ø©"):
                explanation = explain_match(query, row['text'])
                st.write(explanation)
